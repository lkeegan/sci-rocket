# Set min. snakemake version for compatability.
snakemake.utils.min_version("7.32.4")


# Skeleton config, parameters will be overwritten by user-defined config file.
configfile: "examples/example_config.yaml"


# Import modules. ----

import sys
import pandas as pd

## Custom modules.
sys.path.insert(0, "rules/scripts/demultiplexing")
import sanity_checks

# Import samples and barcodes. ----
samples = pd.read_csv(config["path_samples"], sep="\t", dtype=str, comment="#")
barcodes = pd.read_csv(config["path_barcodes"], sep="\t", comment="#")

## Generate the sequencing_name based on the last folder name of the path_bcl or path_fastq.
if "path_fastq" in samples.columns and "path_bcl" in samples.columns:
    print("Both BCL and FASTQ paths are specified in the samples file. Will start from FASTQ.")

if "path_fastq" in samples.columns:
    samples["path_fastq"] = samples["path_fastq"].str.rstrip("/")
    samples["path_bcl"] = samples["path_fastq"]
    samples["sequencing_name"] = samples["path_fastq"].str.split("/").str[-1]
elif "path_bcl" in samples.columns:
    samples["path_bcl"] = samples["path_bcl"].str.rstrip("/")
    samples["sequencing_name"] = samples["path_bcl"].str.split("/").str[-1]
else:
    raise ValueError("Either path_bcl or path_fastq must be specified in the samples file.")

# Sanity checks of inputs. ----
sanity_checks.check_sanity(samples, barcodes, config)

# Select unique samples for which to generate sample-specific files. ----
samples_unique = samples.drop_duplicates( subset=["path_bcl", "sequencing_name", "experiment_name", "sample_name", "species"] )


# Select samples for haplotyping (optional). ----
## Check if strain1 exist.
if("strain1" in samples_unique.columns and "strain2" in samples_unique.columns):
    samples_unique_haplotyping = samples_unique[
        samples_unique[["strain1", "strain2"]].notna().all(axis=1) &
        (samples_unique["species"] == "mouse")
    ]
else:
    samples_unique_haplotyping = pd.DataFrame(columns = ["experiment_name", "sample_name", "strain1", "strain2"])


# Constrain wildcard values to resolve downstream mixtures. ----
wildcard_constraints:
    sequencing_name="|".join(
        [re.escape(str(x)) for x in samples_unique["sequencing_name"]]
    ),
    experiment_name="|".join(
        [re.escape(str(x)) for x in samples_unique["experiment_name"]]
    ),
    sample_name="|".join([re.escape(str(x)) for x in samples_unique["sample_name"]]),
    strain1="|".join([re.escape(str(x)) for x in samples_unique_haplotyping["strain1"]]),
    strain2="|".join([re.escape(str(x)) for x in samples_unique_haplotyping["strain2"]]),


# Workflow output. ----


# Scatter-gather settings.
scattergather:
    fastq_split=config["settings"]["scatter_fastq_split"],


# Set working directory to output directory.
workdir: config["dir_output"]

rule all:
    input:
        # Run sci-rocket demultiplexing pipeline.
        expand("{experiment_name}/sci-dash/", experiment_name=samples_unique["experiment_name"]),
       
        # Optional haplotyping rule (Mus musculus).
        expand(
            "{experiment_name}/haplotyping/{sample_name}_{strain1}_{strain2}_haplotagged_readcounts.txt",
            experiment_name=samples_unique_haplotyping["experiment_name"],
            sample_name=samples_unique_haplotyping["sample_name"],
            strain1=samples_unique_haplotyping["strain1"],
            strain2=samples_unique_haplotyping["strain2"],
        ),


# Load rules ----

include: "rules/common.smk"
include: "rules/step1_bcl2fastq.smk"
include: "rules/step2_demultiplexing_fastq.smk"
include: "rules/step3_alignment.smk"
include: "rules/step4_dashboard.smk"
include: "rules/step5_haplotyping.smk"